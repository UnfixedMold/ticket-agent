{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Number of GPUs: 1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, using CPU\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from helpers.const import HF_HUB_DATASET_ID\n",
    "\n",
    "ds = load_dataset(HF_HUB_DATASET_ID)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_subject_body(example):\n",
    "    return {\n",
    "        \"text\": (example.get(\"subject\") or \"\") + \"\\n\\n\" + (example.get(\"body\") or \"\"),\n",
    "        \"label\": example[\"department\"],\n",
    "    }\n",
    "\n",
    "\n",
    "llm_ds = ds.map(merge_subject_body, remove_columns=ds[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_df = llm_ds[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values percentage:\n",
      "text     0.0\n",
      "label    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values percentage:\")\n",
    "print(llm_df.isna().sum() / len(llm_df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Tech Support     300\n",
       "Billing          200\n",
       "Shipping         200\n",
       "Sales            150\n",
       "Legal            100\n",
       "Customer Care     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    llm_df, test_size=0.2, random_state=42, stratify=llm_df[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {label: i for i, label in enumerate(train_df[\"label\"].unique())}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "train_df[\"label\"] = train_df[\"label\"].map(label2id)\n",
    "test_df[\"label\"] = test_df[\"label\"].map(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasification metrics helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from helpers.classification_metrics import (\n",
    "    get_per_class_metrics_df,\n",
    "    get_train_test_metrics_df,\n",
    ")\n",
    "\n",
    "get_per_class_metrics_df = partial(get_per_class_metrics_df, id2label=id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "\n",
    "dummy_classifier.fit(train_df[\"text\"], train_df[\"label\"])\n",
    "\n",
    "y_train_pred_dummy = dummy_classifier.predict(train_df[\"text\"])\n",
    "y_test_pred_dummy = dummy_classifier.predict(test_df[\"text\"])\n",
    "\n",
    "dummy_metrics = get_train_test_metrics_df(\n",
    "    test_df[\"label\"], y_test_pred_dummy, \"Dummy\", train_df[\"label\"], y_train_pred_dummy\n",
    ")\n",
    "\n",
    "dummy_per_class = get_per_class_metrics_df(test_df[\"label\"], y_test_pred_dummy, \"Dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">train</th>\n",
       "      <th colspan=\"4\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.138462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train                                test                           \n",
       "      accuracy precision recall  f1-score accuracy precision recall  f1-score\n",
       "Dummy      0.3      0.09    0.3  0.138462      0.3      0.09    0.3  0.138462"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Dummy</th>\n",
       "      <th>Legal</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shipping</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tech Support</th>\n",
       "      <td>0.30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sales</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Billing</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer Care</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     precision    recall  f1-score  support\n",
       "model class                                                \n",
       "Dummy Legal               0.00  0.000000  0.000000     20.0\n",
       "      Shipping            0.00  0.000000  0.000000     40.0\n",
       "      Tech Support        0.30  1.000000  0.461538     60.0\n",
       "      Sales               0.00  0.000000  0.000000     30.0\n",
       "      Billing             0.00  0.000000  0.000000     40.0\n",
       "      Customer Care       0.00  0.000000  0.000000     10.0\n",
       "      macro avg           0.05  0.166667  0.076923    200.0\n",
       "      weighted avg        0.09  0.300000  0.138462    200.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuned encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aef96b83978419d8dfffee03ae7ae89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889e8937d2414324b53b3de7124e3c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.615500</td>\n",
       "      <td>1.222697</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.854422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.621945</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.911403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.419261</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.927667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.319340</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.959252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.305443</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.951358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from helpers.const import HF_HUB_MODEL_ID\n",
    "from paths import MODELS_DIR, TRAINING_LOGS_DIR\n",
    "\n",
    "BASE_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "\n",
    "\n",
    "def tokenizer_fn(examples: dict) -> dict:\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\")\n",
    "\n",
    "\n",
    "tokenized_train_ds = train_ds.map(tokenizer_fn, batched=True)\n",
    "tokenized_test_ds = test_ds.map(tokenizer_fn, batched=True)\n",
    "\n",
    "tokenized_train_ds.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    ")\n",
    "tokenized_test_ds.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL_NAME, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=train_df[\"label\"].unique(),\n",
    "    y=train_df[\"label\"].values,\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=\"tensorboard\",\n",
    "    logging_dir=TRAINING_LOGS_DIR / BASE_MODEL_NAME,\n",
    "    output_dir=MODELS_DIR / BASE_MODEL_NAME,\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    weight_decay=0.05,\n",
    "    learning_rate=1e-5,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=HF_HUB_MODEL_ID,\n",
    "    hub_strategy=\"checkpoint\",\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(\n",
    "            weight=class_weights_tensor.to(logits.device)\n",
    "        )\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "trainer = WeightedLossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)],\n",
    ")\n",
    "\n",
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_train_predictions = trainer.predict(tokenized_train_ds)\n",
    "llm_y_pred_train = llm_train_predictions.predictions.argmax(axis=-1)\n",
    "llm_y_true_train = tokenized_train_ds[\"label\"]\n",
    "\n",
    "llm_test_predictions = trainer.predict(tokenized_test_ds)\n",
    "llm_y_pred_test = llm_test_predictions.predictions.argmax(axis=-1)\n",
    "llm_y_true_test = tokenized_test_ds[\"label\"]\n",
    "\n",
    "llm_metrics_df = get_train_test_metrics_df(\n",
    "    llm_y_true_test,\n",
    "    llm_y_pred_test,\n",
    "    \"DistilBERT\",\n",
    "    y_train=llm_y_true_train,\n",
    "    y_train_pred=llm_y_pred_train,\n",
    ")\n",
    "\n",
    "llm_per_class_metrics_df = get_per_class_metrics_df(\n",
    "    llm_y_true_test, llm_y_pred_test, \"DistilBERT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">train</th>\n",
       "      <th colspan=\"4\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DistilBERT</th>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.983346</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.980861</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.962554</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.951358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train                                 test                   \\\n",
       "           accuracy precision  recall  f1-score accuracy precision recall   \n",
       "DistilBERT   0.9825  0.983346  0.9825  0.980861     0.96  0.962554   0.96   \n",
       "\n",
       "                      \n",
       "            f1-score  \n",
       "DistilBERT  0.951358  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">DistilBERT</th>\n",
       "      <th>Legal</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shipping</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tech Support</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sales</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Billing</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer Care</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.961400</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.886253</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.962554</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.951358</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          precision  recall  f1-score  support\n",
       "model      class                                              \n",
       "DistilBERT Legal           0.863636   0.950  0.904762     20.0\n",
       "           Shipping        0.952381   1.000  0.975610     40.0\n",
       "           Tech Support    0.952381   1.000  0.975610     60.0\n",
       "           Sales           1.000000   1.000  1.000000     30.0\n",
       "           Billing         1.000000   1.000  1.000000     40.0\n",
       "           Customer Care   1.000000   0.300  0.461538     10.0\n",
       "           macro avg       0.961400   0.875  0.886253    200.0\n",
       "           weighted avg    0.962554   0.960  0.951358    200.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_per_class_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">train</th>\n",
       "      <th colspan=\"4\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.138462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistilBERT</th>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.983346</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.980861</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.962554</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.951358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train                                 test                   \\\n",
       "           accuracy precision  recall  f1-score accuracy precision recall   \n",
       "Dummy        0.3000  0.090000  0.3000  0.138462     0.30  0.090000   0.30   \n",
       "DistilBERT   0.9825  0.983346  0.9825  0.980861     0.96  0.962554   0.96   \n",
       "\n",
       "                      \n",
       "            f1-score  \n",
       "Dummy       0.138462  \n",
       "DistilBERT  0.951358  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_metrics_df = pd.concat([dummy_metrics, llm_metrics_df], axis=0)\n",
    "\n",
    "all_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc04758a37514da284a1728aa2d0f79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/h3en1x/distilbert-support-tickets-classifier/commit/c8591632c5d4fc26134d3d18a024572d7971dc41', commit_message='End of training', commit_description='', oid='c8591632c5d4fc26134d3d18a024572d7971dc41', pr_url=None, repo_url=RepoUrl('https://huggingface.co/h3en1x/distilbert-support-tickets-classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='h3en1x/distilbert-support-tickets-classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(dataset=HF_HUB_DATASET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e93cfaa55ae4dd2b9475975c77ba5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/h3en1x/distilbert-support-tickets-classifier/commit/c8591632c5d4fc26134d3d18a024572d7971dc41', commit_message='Upload tokenizer', commit_description='', oid='c8591632c5d4fc26134d3d18a024572d7971dc41', pr_url=None, repo_url=RepoUrl('https://huggingface.co/h3en1x/distilbert-support-tickets-classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='h3en1x/distilbert-support-tickets-classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(HF_HUB_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0dfe32a86f48a8a38f4ee87ddbce05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "from helpers.const import HF_HUB_MODEL_ID\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=HF_HUB_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Legal', 'score': 0.48047029972076416}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = \"Website down\"\n",
    "\n",
    "body = \"Hey, I've notices your website is down. Can you please check it?\"\n",
    "\n",
    "prompt = f\"{subject}\\n\\n{body}\"\n",
    "\n",
    "classifier.predict(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ticket-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
